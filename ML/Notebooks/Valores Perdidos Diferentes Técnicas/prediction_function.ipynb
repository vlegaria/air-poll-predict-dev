{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from config.config import MLFLOW_PROJECT, MLFLOW_PWD, MLFLOW_USER, historical_data_1hrfuture, RUTA_MODELOS\n",
    "from sklearn.pipeline import Pipeline\n",
    "import utils.utils\n",
    "from utils.utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging the first models of each station and each problem (O3, for 1 and 24 hrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/09/12 15:11:30 INFO mlflow.tracking.fluent: Experiment with name 'O3 1hr forecast mer' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'O3-mer_1hr_forecast_model'.\n",
      "2024/09/12 15:11:35 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: O3-mer_1hr_forecast_model, version 1\n",
      "Created version '1' of model 'O3-mer_1hr_forecast_model'.\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/09/12 15:11:35 INFO mlflow.tracking.fluent: Experiment with name 'O3 1hr forecast uiz' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'O3-uiz_1hr_forecast_model'.\n",
      "2024/09/12 15:11:38 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: O3-uiz_1hr_forecast_model, version 1\n",
      "Created version '1' of model 'O3-uiz_1hr_forecast_model'.\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/09/12 15:11:38 INFO mlflow.tracking.fluent: Experiment with name 'O3 24hr forecast mer' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'O3-mer_24hr_forecast_model'.\n",
      "2024/09/12 15:11:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: O3-mer_24hr_forecast_model, version 1\n",
      "Created version '1' of model 'O3-mer_24hr_forecast_model'.\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\frank\\OneDrive\\Documents\\Upiita\\Servicio\\calidadAire\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/09/12 15:11:41 INFO mlflow.tracking.fluent: Experiment with name 'O3 24hr forecast uiz' does not exist. Creating a new experiment.\n",
      "Successfully registered model 'O3-uiz_24hr_forecast_model'.\n",
      "2024/09/12 15:11:44 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: O3-uiz_24hr_forecast_model, version 1\n",
      "Created version '1' of model 'O3-uiz_24hr_forecast_model'.\n"
     ]
    }
   ],
   "source": [
    "stations = ['MER', 'UIZ']\n",
    "times_future = [1,24]\n",
    "time_steps = 24\n",
    "target = 'O3'\n",
    "\n",
    "for time_future in times_future:\n",
    "    for station in stations:\n",
    "        # Se carga el archivo de los modelos y del scaler por cada estacion, el target, y el tiempo a predecir\n",
    "        model_dir = RUTA_MODELOS+'air-poll-predict-dev/ML/Modelos/best_model_XGBoost_'+str(time_steps)+'timesteps_O3_'+str(time_future)+'timefuture_'+station+'.pkl'\n",
    "        loaded_model = joblib.load(model_dir)\n",
    "        dir_scaler = RUTA_MODELOS+'air-poll-predict-dev/ML/Scalers/'+station+'_scaler_O3.pkl'\n",
    "        with open(dir_scaler, 'rb') as file:\n",
    "            loaded_scaler = pickle.load(file)\n",
    "\n",
    "        # Se acceden a los datos de su respectiva base de datos, \n",
    "        # se dividen en conjunto de entrenamiento y prueba \n",
    "        # Se evalúan las métricas para registrar el desempeño del modelo\n",
    "        station = station.lower()\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        X, y, df, dates = table_data(table_name, target, station)\n",
    "        X_seq, y_seq = create_sequences2(X, y, time_steps, time_future)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "        predicciones_normalizadas = loaded_model.predict(X_test)\n",
    "        predicciones_normalizadas = predicciones_normalizadas.reshape(-1, 1)\n",
    "        predicciones = loaded_scaler.inverse_transform(predicciones_normalizadas)\n",
    "        y_test_normalizadas = y_test.reshape(-1, 1)\n",
    "        y_test = loaded_scaler.inverse_transform(y_test_normalizadas)\n",
    "        metrics_results = metrics(X_test, y_test, predicciones, printData=False)\n",
    "\n",
    "        MLFLOW_experiment = f\"{target} {time_future}hr forecast {station}\"\n",
    "        mlflow.set_experiment(MLFLOW_experiment)\n",
    "        params = loaded_model.get_params()\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run() as run:\n",
    "            # Log the hyperparameters\n",
    "            mlflow.log_params(params)\n",
    "            run_id = run.info.run_id\n",
    "            \n",
    "            # Log scaler as an artifact\n",
    "            mlflow.log_artifact(dir_scaler, artifact_path=\"artifacts\")\n",
    "\n",
    "            # Log the metrics\n",
    "            for metric_name, value in metrics_results.items():\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "\n",
    "            # Set a tag that we can use to remind ourselves what this run was for\n",
    "            info =  f\"XGboost model for {target}-{time_future} hr prediction, with the {station}-station data\"\n",
    "            mlflow.set_tag(\"Training Info\",info)\n",
    "\n",
    "            # Infer the model signature (la forma de la entrada del modelo)\n",
    "            signature = infer_signature(X_train, loaded_model.predict(X_train))\n",
    "            model_name = f\"{target}-{station}_{time_future}hr_forecast_model\"\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=loaded_model,\n",
    "                artifact_path=f\"{station} station model for {target}-{time_future}hr forecasting\",\n",
    "                signature=signature,\n",
    "                input_example=X_train,\n",
    "                registered_model_name=model_name\n",
    "            )\n",
    "            # Asignar un alias al modelo\n",
    "            client.set_registered_model_alias(model_name, \"champion\", '1')\n",
    "            # Asignar un tag al modelo registrado\n",
    "            client.set_model_version_tag(\n",
    "                name=model_name,\n",
    "                version= '1',\n",
    "                key=\"historicalData\",\n",
    "                value=historical_data_1hrfuture\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"O3-mer_1hr_forecast_model\"\n",
    "best_model_alias = \"champion\"\n",
    "best_model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{best_model_alias}\")\n",
    "best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "best_model_version = best_model_info.version\n",
    "best_model_run_id = best_model_info.run_id\n",
    "station = \"MER\"\n",
    "target = 'O3'\n",
    "time_steps = 24\n",
    "time_future = 1\n",
    "table_name = 'apicalidadaire_'+station+'_norm'\n",
    "X, y, df, dates = table_data(table_name, target, station)\n",
    "data = ingest(df, target, time_steps)\n",
    "norm_predictions = best_model.predict(data)\n",
    "artifacts = client.list_artifacts(best_model_run_id, path=\"artifacts\")\n",
    "scaler_dir = 'artifacts/'+station.upper()+'_scaler_'+target+'.pkl'\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=best_model_run_id, artifact_path=scaler_dir)\n",
    "# Abrir el archivo .pkl descargado\n",
    "with open(local_path, \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "norm_predictions = norm_predictions.reshape(-1, 1)\n",
    "predictions = scaler.inverse_transform(norm_predictions)\n",
    "ozone_value = round(float(predictions),4)\n",
    "print(\"The Ozone value for the next hour is\", ozone_value, \"ppb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de la clase para el predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ozonePredictor():    \n",
    "    def __init__(self,\n",
    "                 train_experiment,\n",
    "                 from_start = False):\n",
    "        self.from_start = from_start\n",
    "        self.train_experiment = train_experiment\n",
    "        \n",
    "    def save(self,path):\n",
    "        joblib.dump(self.model, 'model.pkl')\n",
    "    \n",
    "    def get_model_from_mlflow(self):\n",
    "        return mlflow.sklearn.load_model(self.model_uri)\n",
    "    \n",
    "    def load(self):\n",
    "        if self.from_start:\n",
    "            self.model = Pipeline([\n",
    "                    ('std_scaler',MinMaxScaler()),\n",
    "                    ])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # ------------------------\n",
    "            # Cargar el ultimo modelo registrado\n",
    "            # ------------------------   \n",
    "            model_name = \"O3-mer_1hr_forecast_model\"\n",
    "            alias = \"champion\"\n",
    "            self.model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{alias}\")\n",
    "            \n",
    "    def load_historical_data(self, target, time_steps):\n",
    "        #Conexion con postgress     \n",
    "        engine = create_engine(f'postgresql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}')\n",
    "        esquema = 'public'\n",
    "        # Recuperar los datos y cargar en un DataFrame\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        query = f\"SELECT * FROM {esquema}.{table_name};\"\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "        df = df.tail(time_steps)\n",
    "        X = df.drop(columns=['idData', 'date', 'year', 'month', 'day', 'hour', 'minutes', 'NOX'])\n",
    "        X = X.drop(columns=[target])\n",
    "        array = X.to_numpy()\n",
    "        vector = array.flatten()\n",
    "        return np.array([vector])\n",
    "            \n",
    "    def load_dataset(table_name, target,station,time_steps, time_future, test_size):\n",
    "        engine = create_engine(f'postgresql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}')\n",
    "        esquema = 'public'\n",
    "        # Recuperar los datos y cargar en un DataFrame\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        query = f\"SELECT * FROM {esquema}.{table_name};\"\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "        dates = df.date\n",
    "        y = df[target]\n",
    "        X = df.drop(columns=['idData', 'date', 'year', 'month', 'day', 'hour', 'minutes', 'NOX'])\n",
    "        X = X.drop(columns=[target])\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - time_steps-time_future):\n",
    "            df = X[i:(i + time_steps)]\n",
    "            array = df.to_numpy()\n",
    "            # Aplanar el array a un vector\n",
    "            vector = array.flatten()\n",
    "            Xs.append(vector)\n",
    "            ys.append(y[i + time_steps+time_future])\n",
    "        X_seq = np.array(Xs)\n",
    "        y_seq = np.array(ys)\n",
    "        # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=test_size, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def predict(self,data):\n",
    "        #data = [CO, NO, NO2, SO2, PM10, PM25, RH, TMP, TRFC..etc]\n",
    "        predictions =  self.model.predict(data)\n",
    "        return predictions\n",
    "        \n",
    "                \n",
    "    def train(self,):\n",
    "        # ------------------------\n",
    "        # Acceder a los registros de MLflow\n",
    "        # ------------------------   \n",
    "        # Si no existe el experimento, lo crea y configura para registrar los parámetros del modelo\n",
    "        if not mlflow.get_experiment_by_name(self.train_experiment):\n",
    "            mlflow.create_experiment(name=self.train_experiment)\n",
    "        # URL y puerto del servidor MLFLOW\n",
    "        mlflow.set_experiment(self.train_experiment)\n",
    "        experiment = mlflow.get_experiment_by_name(self.train_experiment)\n",
    "        \n",
    "        # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        target = 'O3'\n",
    "        station = 'mer'\n",
    "        time_steps = 24\n",
    "        time_future = 1\n",
    "        test_size = 0.2\n",
    "        X_train, X_test, y_train, y_test = self.load_dataset(table_name, target,station,time_steps, time_future, test_size)\n",
    "        # ------------------------\n",
    "        # 5 Entrenamiento\n",
    "        # ------------------------\n",
    "        # Definir los parámetros para GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.05, 0.1]\n",
    "        }\n",
    "        retrain_model = GridSearchCV(estimator=self.model, param_grid=param_grid, cv=5, scoring='r2',return_train_score=True)\n",
    "        # Entrenar GridSearchCV\n",
    "        retrain_model.fit(X_train, y_train)\n",
    "\n",
    "        mlflow.set_experiment(MLFLOW_PROJECT)\n",
    "        run_name = f\"{target}-{time_future}hr-{station}test\"\n",
    "        params = loaded_model.get_params()\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run() as run:\n",
    "            # Log the hyperparameters\n",
    "            mlflow.log_params(params)\n",
    "            run_id = run.info.run_id\n",
    "\n",
    "            with open(dir_scaler, 'rb') as file:\n",
    "                loaded_scaler = pickle.load(file)\n",
    "            \n",
    "            # Loguear el archivo JSON como un artifact en MLflow\n",
    "            mlflow.log_artifact(dir_scaler, artifact_path=\"artifacts\")\n",
    "\n",
    "\n",
    "            # Log the loss metric\n",
    "            for metric_name, value in metrics_results.items():\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "\n",
    "            # Set a tag that we can use to remind ourselves what this run was for\n",
    "            info =  f\"XGboost model for {target}-{time_future} hr prediction, with the {station}-station data\"\n",
    "            mlflow.set_tag(\"Training Info\",info)\n",
    "\n",
    "            # Infer the model signature\n",
    "            signature = infer_signature(X_train, retrain_model.predict(X_train))\n",
    "            model_name = f\"{target}-{station}_{time_future}hr_forecast_model\"\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=retrain_model,\n",
    "                artifact_path=f\"{station} station model for {target}-{time_future}hr forecasting\",\n",
    "                signature=signature,\n",
    "                input_example=X_train,\n",
    "            )\n",
    "\n",
    "            model_uri = f\"runs:/{run_id}/{station} station model for {target}-{time_future}hr forecasting\".format(run.info.run_id)\n",
    "            mv = client.create_model_version(model_name, model_uri, run.info.run_id)\n",
    "            # Set registered model alias\n",
    "            client.set_registered_model_alias(model_name, \"validation_status\", mv.version)\n",
    "            # Asignar un tag al modelo registrado\n",
    "            client.set_model_version_tag(\n",
    "                name=model_name,\n",
    "                version= mv.version,\n",
    "                key=\"historicalData\",\n",
    "                value=historical_data_1hrfuture\n",
    "            )\n",
    "            #Pregunta si el nuevo modelo es mejor que el último mejor modelo registrado\n",
    "            #De ser así, registra el nuevo modelo como el mejor bajo el alias de \"champion\"\n",
    "            client = MlflowClient()\n",
    "            model_name = \"O3-mer_1hr_forecast_model\"\n",
    "            best_model_alias = \"champion\"\n",
    "            best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "            best_model_version = best_model_info.version\n",
    "            best_model_run_id = best_model_info.run_id\n",
    "            # Acceder a las métricas del mejor modelo\n",
    "            best_metrics = client.get_run(best_model_run_id).data.metrics\n",
    "            # Comparar las métricas del modelo actual con el mejor modelo hasta el momento\n",
    "            if metrics_results[\"r2adjusted\"] > best_metrics[\"r2adjusted\"] and metrics_results[\"rmse\"] < best_metrics[\"rmse\"]:\n",
    "                #Registra el nuevo modelo como el mejor\n",
    "                client.set_registered_model_alias(model_name, best_model_alias, mv.version)\n",
    "                client.delete_registered_model_alias(model_name, \"validation_status\") \n",
    "                client.set_registered_model_alias(model_name, \"old_champion\", best_model_version)\n",
    "            else:\n",
    "                print(\"No se mejoró el modelo\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128.000:8080/predict\n",
    "#def predict():\n",
    "datetime_now = datetime.now()\n",
    "print(datetime_now)\n",
    "date = pd.to_datetime(\n",
    "                datetime_now,\n",
    "                format='%d/%m/%Y %H:%M:%S',\n",
    "                dayfirst=True,\n",
    "                errors='coerce'\n",
    "            )\n",
    "date = date.dt.round('H')\n",
    "print(date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
