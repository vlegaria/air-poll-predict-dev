{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función para realizar las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "#import sklearn\n",
    "import pickle\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from config.config import MLFLOW_PROJECT, MLFLOW_PWD, MLFLOW_USER, historical_data_1hrfuture\n",
    "from sklearn.pipeline import Pipeline\n",
    "#import os\n",
    "import utils.utils\n",
    "from utils.utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "#from config.config import DATABASE_HOST, DATABASE_USER, DATABASE_PASSWORD, DATABASE_NAME, DATABASE_PORT\n",
    "#from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = 'mer'\n",
    "table_name = 'apicalidadaire_'+station+'_norm'\n",
    "target = 'O3'\n",
    "X, y, df, dates = table_data(table_name, target, station)\n",
    "time_steps = 24\n",
    "time_future =1\n",
    "X_seq, y_seq = create_sequences2(X, y, time_steps, time_future)\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.792765\n",
      "R^2 ajustado: 1.476641\n",
      "RMSE 16.178246\n",
      "MAE: 11.134049\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'C:/Users/valer/Documents/CIC/doctorado/Proyecto_Innovacion/air-poll-predict-dev/ML/Modelos/best_model_XGBoost_24timesteps_O3_1timefuture_MER_2024-08-06 12_34.pkl'\n",
    "loaded_model = joblib.load(model_dir)\n",
    "dir_scaler = 'C:/Users/valer/Documents/CIC/doctorado/Proyecto_Innovacion/air-poll-predict-dev/ML/Scalers/MER_scaler_O3.pkl'\n",
    "with open(dir_scaler, 'rb') as file:\n",
    "    loaded_scaler = pickle.load(file)\n",
    "\n",
    "predicciones_normalizadas = loaded_model.predict(X_test)\n",
    "predicciones_normalizadas = predicciones_normalizadas.reshape(-1, 1)\n",
    "predicciones = loaded_scaler.inverse_transform(predicciones_normalizadas)\n",
    "y_test_normalizadas = y_test.reshape(-1, 1)\n",
    "y_test = loaded_scaler.inverse_transform(y_test_normalizadas)\n",
    "metrics_results = metrics(X_test, y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valer\\anaconda3\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(MLFLOW_PROJECT)\n",
    "run_name = f\"{target}-{time_future}hr-{station}test\"\n",
    "params = loaded_model.get_params()\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    with open(dir_scaler, 'rb') as file:\n",
    "        loaded_scaler = pickle.load(file)\n",
    "    \n",
    "    # Loguear el archivo JSON como un artifact en MLflow\n",
    "    mlflow.log_artifact(dir_scaler, artifact_path=\"artifacts\")\n",
    "\n",
    "\n",
    "    # Log the loss metric\n",
    "    for metric_name, value in metrics_results.items():\n",
    "        mlflow.log_metric(metric_name, value)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    info =  f\"XGboost model for {target}-{time_future} hr prediction, with the {station}-station data\"\n",
    "    mlflow.set_tag(\"Training Info\",info)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, loaded_model.predict(X_train))\n",
    "    model_name = f\"{target}-{station}_{time_future}hr_forecast_model\"\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=loaded_model,\n",
    "        artifact_path=f\"{station} station model for {target}-{time_future}hr forecasting\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 21:54:37 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: O3-MER_1hr_forecast_model, version 13\n"
     ]
    }
   ],
   "source": [
    "# Create a new version of the rfr model under the registered model name\n",
    "#model_uri = \"runs:/{}/sklearn-model\".format(run.info.run_id)\n",
    "model_uri = f\"runs:/{run_id}/mer station model for O3-1hr forecasting\".format(run.info.run_id)\n",
    "mv = client.create_model_version(model_name, model_uri, run.info.run_id)\n",
    "# Set registered model alias\n",
    "client.set_registered_model_alias(model_name, \"validation_status\", mv.version)\n",
    "# Asignar un tag al modelo registrado\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version= mv.version,\n",
    "    key=\"historicalData\",\n",
    "    value=historical_data_1hrfuture\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registrar como el mejor modelo, si supero las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas del run: 96eab81bee814307ba32388fcef4142b\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "model_name = \"O3-mer_1hr_forecast_model\"\n",
    "best_model_alias = \"champion\"\n",
    "#best_model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{best_model_alias}\")\n",
    "best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "best_model_version = best_model_info.version\n",
    "best_model_run_id = best_model_info.run_id\n",
    "# Acceder a las métricas del mejor modelo\n",
    "best_metrics = client.get_run(best_model_run_id).data.metrics\n",
    "# Comparar las métricas del modelo actual con el mejor modelo hasta el momento\n",
    "print(\"Métricas del run:\", run_id)\n",
    "if metrics_results[\"r2adjusted\"] > best_metrics[\"r2adjusted\"] and metrics_results[\"rmse\"] < best_metrics[\"rmse\"]:\n",
    "    #Registra el nuevo modelo como el mejor\n",
    "    client.set_registered_model_alias(model_name, best_model_alias, mv.version)\n",
    "    client.delete_registered_model_alias(model_name, \"validation_status\") \n",
    "    client.set_registered_model_alias(model_name, \"old_champion\", best_model_version)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f024b7c61da64eb18e29b4fb6787d26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"O3-mer_1hr_forecast_model\"\n",
    "alias = \"champion\"\n",
    "best_model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{alias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11871517], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station = \"MER\"\n",
    "X, y, df, dates = table_data(table_name, target, station)\n",
    "data = ingest(df, target, time_steps)\n",
    "norm_predictions = best_model.predict(data)\n",
    "norm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1090ae21d0284403b59800d1f9955ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artifacts = client.list_artifacts(run_id, path=\"artifacts\")\n",
    "local_path = mlflow.artifacts.download_artifacts(run_id=run_id, artifact_path=\"artifacts/MER_scaler_O3.pkl\")\n",
    "\n",
    "# Abrir el archivo .pkl descargado\n",
    "with open(local_path, \"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ozone value for the next hour is 19.7067 ppb\n"
     ]
    }
   ],
   "source": [
    "norm_predictions = norm_predictions.reshape(-1, 1)\n",
    "predictions = loaded_scaler.inverse_transform(norm_predictions)\n",
    "ozone_value = round(float(predictions),4)\n",
    "print(\"The Ozone value for the next hour is\", ozone_value, \"ppb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ozonePredictor():    \n",
    "    def __init__(self,\n",
    "                 train_experiment,\n",
    "                 from_start = False):\n",
    "        self.from_start = from_start\n",
    "        self.train_experiment = train_experiment\n",
    "        \n",
    "    def save(self,path):\n",
    "        joblib.dump(self.model, 'model.pkl')\n",
    "    \n",
    "    def get_model_from_mlflow(self):\n",
    "        return mlflow.sklearn.load_model(self.model_uri)\n",
    "    \n",
    "    def load(self):\n",
    "        if self.from_start:\n",
    "            self.model = Pipeline([\n",
    "                    ('std_scaler',MinMaxScaler()),\n",
    "                    ])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # ------------------------\n",
    "            # Cargar el ultimo modelo registrado\n",
    "            # ------------------------   \n",
    "            #self.model = mlflow.pytorch.load_model(model_uri)\n",
    "            model_name = \"O3-mer_1hr_forecast_model\"\n",
    "            alias = \"champion\"\n",
    "            self.model = mlflow.pyfunc.load_model(f\"models:/{model_name}@{alias}\")\n",
    "            \n",
    "    def load_historical_data(self, target, time_steps):\n",
    "        #Conexion con postgress     \n",
    "        engine = create_engine(f'postgresql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}')\n",
    "        esquema = 'public'\n",
    "        # Recuperar los datos y cargar en un DataFrame\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        query = f\"SELECT * FROM {esquema}.{table_name};\"\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "        df = df.tail(time_steps)\n",
    "        X = df.drop(columns=['idData', 'date', 'year', 'month', 'day', 'hour', 'minutes', 'NOX'])\n",
    "        X = X.drop(columns=[target])\n",
    "        array = X.to_numpy()\n",
    "        vector = array.flatten()\n",
    "        return np.array([vector])\n",
    "            \n",
    "    def load_dataset(table_name, target,station,time_steps, time_future, test_size):\n",
    "        engine = create_engine(f'postgresql://{DATABASE_USER}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_NAME}')\n",
    "        esquema = 'public'\n",
    "        # Recuperar los datos y cargar en un DataFrame\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        query = f\"SELECT * FROM {esquema}.{table_name};\"\n",
    "        df = pd.read_sql_query(query, engine)\n",
    "        dates = df.date\n",
    "        y = df[target]\n",
    "        X = df.drop(columns=['idData', 'date', 'year', 'month', 'day', 'hour', 'minutes', 'NOX'])\n",
    "        X = X.drop(columns=[target])\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - time_steps-time_future):\n",
    "            df = X[i:(i + time_steps)]\n",
    "            array = df.to_numpy()\n",
    "            # Aplanar el array a un vector\n",
    "            vector = array.flatten()\n",
    "            Xs.append(vector)\n",
    "            ys.append(y[i + time_steps+time_future])\n",
    "        X_seq = np.array(Xs)\n",
    "        y_seq = np.array(ys)\n",
    "        # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=test_size, random_state=42)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def predict(self,data):\n",
    "        #data = [CO, NO, NO2, SO2, PM10, PM25, RH, TMP, TRFC..etc]\n",
    "        predictions =  self.model.predict(data)\n",
    "        return predictions\n",
    "        \n",
    "                \n",
    "    def train(self,):\n",
    "        # ------------------------\n",
    "        # Acceder a los registros de MLflow\n",
    "        # ------------------------   \n",
    "        # Si no existe el experimento, lo crea y configura para registrar los parámetros del modelo\n",
    "        if not mlflow.get_experiment_by_name(self.train_experiment):\n",
    "            mlflow.create_experiment(name=self.train_experiment)\n",
    "        # URL y puerto del servidor MLFLOW\n",
    "        mlflow.set_experiment(self.train_experiment)\n",
    "        experiment = mlflow.get_experiment_by_name(self.train_experiment)\n",
    "        \n",
    "        # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "        table_name = 'apicalidadaire_'+station+'_norm'\n",
    "        target = 'O3'\n",
    "        station = 'mer'\n",
    "        time_steps = 24\n",
    "        time_future = 1\n",
    "        test_size = 0.2\n",
    "        X_train, X_test, y_train, y_test = self.load_dataset(table_name, target,station,time_steps, time_future, test_size)\n",
    "        # ------------------------\n",
    "        # 5 Entrenamiento\n",
    "        # ------------------------\n",
    "        # Definir los parámetros para GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'learning_rate': [0.01, 0.05, 0.1]\n",
    "        }\n",
    "        retrain_model = GridSearchCV(estimator=self.model, param_grid=param_grid, cv=5, scoring='r2',return_train_score=True)\n",
    "        # Entrenar GridSearchCV\n",
    "        retrain_model.fit(X_train, y_train)\n",
    "\n",
    "        mlflow.set_experiment(MLFLOW_PROJECT)\n",
    "        run_name = f\"{target}-{time_future}hr-{station}test\"\n",
    "        params = loaded_model.get_params()\n",
    "        # Start an MLflow run\n",
    "        with mlflow.start_run() as run:\n",
    "            # Log the hyperparameters\n",
    "            mlflow.log_params(params)\n",
    "            run_id = run.info.run_id\n",
    "\n",
    "            with open(dir_scaler, 'rb') as file:\n",
    "                loaded_scaler = pickle.load(file)\n",
    "            \n",
    "            # Loguear el archivo JSON como un artifact en MLflow\n",
    "            mlflow.log_artifact(dir_scaler, artifact_path=\"artifacts\")\n",
    "\n",
    "\n",
    "            # Log the loss metric\n",
    "            for metric_name, value in metrics_results.items():\n",
    "                mlflow.log_metric(metric_name, value)\n",
    "\n",
    "            # Set a tag that we can use to remind ourselves what this run was for\n",
    "            info =  f\"XGboost model for {target}-{time_future} hr prediction, with the {station}-station data\"\n",
    "            mlflow.set_tag(\"Training Info\",info)\n",
    "\n",
    "            # Infer the model signature\n",
    "            signature = infer_signature(X_train, retrain_model.predict(X_train))\n",
    "            model_name = f\"{target}-{station}_{time_future}hr_forecast_model\"\n",
    "            # Log the model\n",
    "            model_info = mlflow.sklearn.log_model(\n",
    "                sk_model=retrain_model,\n",
    "                artifact_path=f\"{station} station model for {target}-{time_future}hr forecasting\",\n",
    "                signature=signature,\n",
    "                input_example=X_train,\n",
    "            )\n",
    "\n",
    "            model_uri = f\"runs:/{run_id}/mer station model for O3-1hr forecasting\".format(run.info.run_id)\n",
    "            mv = client.create_model_version(model_name, model_uri, run.info.run_id)\n",
    "            # Set registered model alias\n",
    "            client.set_registered_model_alias(model_name, \"validation_status\", mv.version)\n",
    "            # Asignar un tag al modelo registrado\n",
    "            client.set_model_version_tag(\n",
    "                name=model_name,\n",
    "                version= mv.version,\n",
    "                key=\"historicalData\",\n",
    "                value=historical_data_1hrfuture\n",
    "            )\n",
    "            #Pregunta si el nuevo modelo es mejor que el último mejor modelo registrado\n",
    "            #De ser así, registra el nuevo modelo como el mejor bajo el alias de \"champion\"\n",
    "            client = MlflowClient()\n",
    "            model_name = \"O3-mer_1hr_forecast_model\"\n",
    "            best_model_alias = \"champion\"\n",
    "            best_model_info = client.get_model_version_by_alias(model_name, best_model_alias)\n",
    "            best_model_version = best_model_info.version\n",
    "            best_model_run_id = best_model_info.run_id\n",
    "            # Acceder a las métricas del mejor modelo\n",
    "            best_metrics = client.get_run(best_model_run_id).data.metrics\n",
    "            # Comparar las métricas del modelo actual con el mejor modelo hasta el momento\n",
    "            if metrics_results[\"r2adjusted\"] > best_metrics[\"r2adjusted\"] and metrics_results[\"rmse\"] < best_metrics[\"rmse\"]:\n",
    "                #Registra el nuevo modelo como el mejor\n",
    "                client.set_registered_model_alias(model_name, best_model_alias, mv.version)\n",
    "                client.delete_registered_model_alias(model_name, \"validation_status\") \n",
    "                client.set_registered_model_alias(model_name, \"old_champion\", best_model_version)\n",
    "            else:\n",
    "                print(\"No se mejoró el modelo\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128.000:8080/predict\n",
    "#def predict():\n",
    "datetime_now = datetime.now()\n",
    "print(datetime_now)\n",
    "date = pd.to_datetime(\n",
    "                datetime_now,\n",
    "                format='%d/%m/%Y %H:%M:%S',\n",
    "                dayfirst=True,\n",
    "                errors='coerce'\n",
    "            )\n",
    "date = date.dt.round('H')\n",
    "print(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MlflowClient' object has no attribute 'list_registered_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m         client\u001b[38;5;241m.\u001b[39mdelete_experiment(experiment\u001b[38;5;241m.\u001b[39mexperiment_id)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Ejecutar las funciones\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m delete_all_model_versions()\n\u001b[0;32m     25\u001b[0m delete_all_experiments()\n",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m, in \u001b[0;36mdelete_all_model_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete_all_model_versions\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     registered_models \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mlist_registered_models()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m registered_models:\n\u001b[0;32m     10\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MlflowClient' object has no attribute 'list_registered_models'"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Crear un cliente de MLflow\n",
    "client = MlflowClient()\n",
    "\n",
    "# Borrar todas las versiones de todos los modelos registrados\n",
    "def delete_all_model_versions():\n",
    "    registered_models = client.list_registered_models()\n",
    "    for model in registered_models:\n",
    "        model_name = model.name\n",
    "        versions = client.get_latest_versions(model_name, stages=[\"None\", \"Staging\", \"Production\", \"Archived\"])\n",
    "        for version in versions:\n",
    "            client.delete_model_version(model_name, version.version)\n",
    "        # Opcional: eliminar el registro del modelo si no quedan versiones\n",
    "        client.delete_registered_model(model_name)\n",
    "\n",
    "# Borrar todos los experimentos\n",
    "def delete_all_experiments():\n",
    "    experiments = client.list_experiments()\n",
    "    for experiment in experiments:\n",
    "        client.delete_experiment(experiment.experiment_id)\n",
    "\n",
    "# Ejecutar las funciones\n",
    "delete_all_model_versions()\n",
    "delete_all_experiments()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
